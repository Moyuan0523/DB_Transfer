#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MSSQL åˆ° MariaDB è³‡æ–™åº«é·ç§»ç¨‹å¼
åŸºæ–¼åŸæœ‰ MSSQL ç¨‹å¼é€²è¡Œæ“´å±•ï¼Œå¯¦ç¾å®Œæ•´çš„è³‡æ–™åº«é·ç§»åŠŸèƒ½
"""

import pandas as pd
import pyodbc
import mysql.connector
import argparse
import os
import sys
import re
import json
import hashlib
from sqlalchemy import create_engine, text
from sqlalchemy.engine import URL
import urllib.parse
import time
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional

class DatabaseMigrator:
    """è³‡æ–™åº«é·ç§»æ ¸å¿ƒé¡åˆ¥"""
    
    def __init__(self, mssql_config: Dict, mariadb_config: Dict, batch_size: int = 1000):
        self.mssql_config = mssql_config
        self.mariadb_config = mariadb_config
        self.batch_size = batch_size
        self.migration_log = []
        self.verification_results = {}
        self.mssql_config = mssql_config
        self.mariadb_config = mariadb_config
        self.batch_size = batch_size
        self.migration_log = []
        self.verification_results = {}

        # æ–°å¢ï¼šSQLAlchemyå¼•æ“
        self.mssql_engine = None
        self.mariadb_engine = None
        
        # è¨­ç½®è©³ç´°æ—¥èªŒ
        self.setup_logging()
        
        # è³‡æ–™é¡å‹æ˜ å°„è¡¨
        self.datatype_mapping = {
            'int': 'INT',
            'bigint': 'BIGINT',
            'smallint': 'SMALLINT',
            'tinyint': 'TINYINT',
            'bit': 'BOOLEAN',
            'decimal': 'DECIMAL',
            'numeric': 'DECIMAL',
            'money': 'DECIMAL(19,4)',
            'float': 'DOUBLE',
            'real': 'FLOAT',
            'datetime': 'DATETIME',
            'datetime2': 'DATETIME',
            'date': 'DATE',
            'time': 'TIME',
            'varchar': 'VARCHAR',
            'nvarchar': 'VARCHAR',
            'char': 'CHAR',
            'nchar': 'CHAR',
            'text': 'TEXT',
            'ntext': 'LONGTEXT',
            'uniqueidentifier': 'VARCHAR(36)'
        }
    
    def setup_logging(self):
        """è¨­ç½®æ—¥èªŒç³»çµ±"""
        # å‰µå»ºæ—¥èªŒç›®éŒ„
        os.makedirs('migration_logs', exist_ok=True)
        
        # è¨­ç½®ä¸»æ—¥èªŒ
        self.logger = logging.getLogger('DatabaseMigrator')
        self.logger.setLevel(logging.INFO)
        
        # æ¸…é™¤ç¾æœ‰è™•ç†å™¨
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # æ–‡ä»¶è™•ç†å™¨
        file_handler = logging.FileHandler(
            f'migration_logs/migration_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log',
            encoding='utf-8'
        )
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°è™•ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # è¨­ç½®æ ¼å¼
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
    
    def connect_mssql(self) -> Optional[pyodbc.Connection]:
        """é€£æ¥MSSQLè³‡æ–™åº«"""
        server = self.mssql_config['server']
        database = self.mssql_config['database']
        
        # æ¸…ç†ä¼ºæœå™¨åç¨±ä¸­çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        server = server.strip()
        
        if self.mssql_config.get('use_windows_auth', False):
            # Windowsé©—è­‰é€£æ¥å­—ä¸²ï¼ˆç°¡åŒ–ä½†ç©©å®šçš„æ–¹å¼ï¼‰
            connection_attempts = [
                # æ¨™æº–Windowsé©—è­‰æ ¼å¼
                f"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes",
                # å˜—è©¦ä¸åŒçš„Trusted_Connectionå€¼
                f"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=true",
                f"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Integrated Security=SSPI",
                # å˜—è©¦èˆŠç‰ˆé©…å‹•ç¨‹å¼
                f"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes",
            ]
        else:
            # SQL Serveré©—è­‰
            username = self.mssql_config.get('username', '')
            password = self.mssql_config.get('password', '')
            connection_attempts = [
                f"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}",
                f"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}",
            ]
        
        # é€ä¸€å˜—è©¦é€£æ¥
        for i, conn_str in enumerate(connection_attempts, 1):
            try:
                self.logger.info(f"å˜—è©¦é€£æ¥æ–¹å¼ {i}")
                self.logger.debug(f"é€£æ¥å­—ä¸²: {conn_str}")
                
                conn = pyodbc.connect(conn_str, timeout=15)
                self.logger.info(f"âœ… æˆåŠŸé€£æ¥åˆ°MSSQLè³‡æ–™åº«: {database}")
                
                # æ¸¬è©¦é€£æ¥
                cursor = conn.cursor()
                cursor.execute("SELECT @@SERVERNAME, DB_NAME()")
                result = cursor.fetchone()
                self.logger.info(f"ä¼ºæœå™¨: {result[0]}, è³‡æ–™åº«: {result[1]}")
                cursor.close()
                
                return conn
                
            except Exception as e:
                self.logger.warning(f"âŒ é€£æ¥æ–¹å¼ {i} å¤±æ•—: {str(e)}")
                continue
        
        # æ‰€æœ‰é€£æ¥æ–¹å¼éƒ½å¤±æ•—
        self.logger.error("ğŸ”´ æ‰€æœ‰é€£æ¥æ–¹å¼éƒ½å¤±æ•—ï¼")
        self.logger.error("è«‹æª¢æŸ¥ä»¥ä¸‹é …ç›®ï¼š")
        self.logger.error("1. SQL Serveræœå‹™é‹è¡Œç‹€æ…‹: net start MSSQL$SQLEXPRESS")
        self.logger.error("2. ä¼ºæœå™¨åç¨±æ˜¯å¦æ­£ç¢º")  
        self.logger.error("3. è³‡æ–™åº«åç¨±æ˜¯å¦å­˜åœ¨")
        self.logger.error("4. Windowsç”¨æˆ¶æ˜¯å¦æœ‰è³‡æ–™åº«æ¬Šé™")
        return None
    
    def connect_mariadb(self) -> Optional[mysql.connector.MySQLConnection]:
        """é€£æ¥MariaDBè³‡æ–™åº«"""
        try:
            conn = mysql.connector.connect(
                host=self.mariadb_config['host'],
                port=self.mariadb_config.get('port', 3306),
                database=self.mariadb_config['database'],
                user=self.mariadb_config['username'],
                password=self.mariadb_config['password'],
                charset='utf8mb4',
                autocommit=False
            )
            self.logger.info(f"æˆåŠŸé€£æ¥åˆ°MariaDBè³‡æ–™åº«: {self.mariadb_config['database']}")
            return conn
        except Exception as e:
            self.logger.error(f"é€£æ¥MariaDBè³‡æ–™åº«å¤±æ•—: {str(e)}")
            return None
    
    def get_mssql_tables(self, schema: str = 'dbo') -> List[str]:
        """ç²å–MSSQLä¸­çš„æ‰€æœ‰è¡¨æ ¼åç¨±ï¼ˆSQLAlchemyç‰ˆæœ¬ï¼‰"""
        engine = self.create_mssql_engine()
        if not engine:
            return []
        
        try:
            query = text("""
                SELECT TABLE_NAME 
                FROM INFORMATION_SCHEMA.TABLES 
                WHERE TABLE_SCHEMA = :schema 
                AND TABLE_TYPE = 'BASE TABLE'
                ORDER BY TABLE_NAME
            """)
            
            with engine.connect() as conn:
                result = conn.execute(query, {"schema": schema})
                tables = [row[0] for row in result.fetchall()]
            
            self.logger.info(f"æ‰¾åˆ° {len(tables)} å€‹è¡¨æ ¼: {', '.join(tables)}")
            return tables
            
        except Exception as e:
            self.logger.error(f"ç²å–è¡¨æ ¼åˆ—è¡¨å¤±æ•—: {str(e)}")
            return []
    
    def get_table_schema(self, table_name: str, schema: str = 'dbo') -> Tuple[List, List, List]:
        """ç²å–è¡¨æ ¼çµæ§‹ä¿¡æ¯ï¼ˆä¿®å¾©ç‰ˆæœ¬ï¼‰"""
        conn = self.connect_mssql()
        if not conn:
            return [], [], []
        
        try:
            cursor = conn.cursor()
            
            # å…ˆæª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            self.logger.info(f"æª¢æŸ¥è¡¨æ ¼ {schema}.{table_name} æ˜¯å¦å­˜åœ¨...")
            cursor.execute(f"""
                SELECT COUNT(*) 
                FROM INFORMATION_SCHEMA.TABLES 
                WHERE TABLE_NAME = ? AND TABLE_SCHEMA = ?
            """, table_name, schema)
            
            table_exists = cursor.fetchone()[0] > 0
            if not table_exists:
                self.logger.warning(f"è¡¨æ ¼ {schema}.{table_name} ä¸å­˜åœ¨")
                
                # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è¡¨æ ¼
                cursor.execute("""
                    SELECT TABLE_SCHEMA, TABLE_NAME 
                    FROM INFORMATION_SCHEMA.TABLES 
                    WHERE TABLE_TYPE = 'BASE TABLE'
                    ORDER BY TABLE_SCHEMA, TABLE_NAME
                """)
                available_tables = cursor.fetchall()
                self.logger.info("å¯ç”¨çš„è¡¨æ ¼:")
                for t_schema, t_name in available_tables:
                    self.logger.info(f"  - {t_schema}.{t_name}")
                
                cursor.close()
                conn.close()
                return [], [], []
            
            # æ–¹æ³•1: ä½¿ç”¨INFORMATION_SCHEMAï¼ˆæ¨è–¦ï¼‰
            self.logger.info(f"æ–¹æ³•1: ä½¿ç”¨INFORMATION_SCHEMAç²å–è¡¨æ ¼çµæ§‹...")
            try:
                cursor.execute(f"""
                    SELECT 
                        COLUMN_NAME,
                        DATA_TYPE,
                        CHARACTER_MAXIMUM_LENGTH,
                        NUMERIC_PRECISION,
                        NUMERIC_SCALE,
                        IS_NULLABLE,
                        COLUMN_DEFAULT
                    FROM INFORMATION_SCHEMA.COLUMNS 
                    WHERE TABLE_NAME = ? AND TABLE_SCHEMA = ?
                    ORDER BY ORDINAL_POSITION
                """, table_name, schema)
                columns = cursor.fetchall()
                
                if columns:
                    self.logger.info(f"âœ… æˆåŠŸç²å– {len(columns)} å€‹æ¬„ä½")
                else:
                    self.logger.warning("âŒ INFORMATION_SCHEMA æ²’æœ‰è¿”å›ä»»ä½•æ¬„ä½")
                    
            except Exception as e:
                self.logger.warning(f"INFORMATION_SCHEMA æŸ¥è©¢å¤±æ•—: {e}")
                columns = []
            
            # æ–¹æ³•2: å¦‚æœæ–¹æ³•1å¤±æ•—ï¼Œä½¿ç”¨sys.columnsï¼ˆå‚™ç”¨æ–¹æ³•ï¼‰
            if not columns:
                self.logger.info(f"æ–¹æ³•2: ä½¿ç”¨sys.columnsç²å–è¡¨æ ¼çµæ§‹...")
                try:
                    cursor.execute(f"""
                        SELECT 
                            c.name as column_name,
                            t.name as data_type,
                            CASE 
                                WHEN t.name IN ('varchar', 'nvarchar', 'char', 'nchar') 
                                THEN CASE WHEN c.max_length = -1 THEN NULL ELSE c.max_length END
                                ELSE NULL 
                            END as character_maximum_length,
                            CASE 
                                WHEN t.name IN ('decimal', 'numeric', 'float', 'real') 
                                THEN c.precision 
                                ELSE NULL 
                            END as numeric_precision,
                            CASE 
                                WHEN t.name IN ('decimal', 'numeric') 
                                THEN c.scale 
                                ELSE NULL 
                            END as numeric_scale,
                            CASE WHEN c.is_nullable = 1 THEN 'YES' ELSE 'NO' END as is_nullable,
                            d.definition as column_default
                        FROM sys.columns c
                        INNER JOIN sys.types t ON c.user_type_id = t.user_type_id
                        INNER JOIN sys.tables tb ON c.object_id = tb.object_id
                        INNER JOIN sys.schemas s ON tb.schema_id = s.schema_id
                        LEFT JOIN sys.default_constraints d ON c.default_object_id = d.object_id
                        WHERE tb.name = ? AND s.name = ?
                        ORDER BY c.column_id
                    """, table_name, schema)
                    
                    columns = cursor.fetchall()
                    
                    if columns:
                        self.logger.info(f"âœ… ä½¿ç”¨sys.columnsæˆåŠŸç²å– {len(columns)} å€‹æ¬„ä½")
                    else:
                        self.logger.error("âŒ sys.columns ä¹Ÿæ²’æœ‰è¿”å›ä»»ä½•æ¬„ä½")
                        
                except Exception as e:
                    self.logger.error(f"sys.columns æŸ¥è©¢å¤±æ•—: {e}")
                    columns = []
            
            # æ–¹æ³•3: æœ€å¾Œçš„å˜—è©¦ - ä½¿ç”¨ç°¡å–®æŸ¥è©¢ç²å–åŸºæœ¬çµæ§‹
            if not columns:
                self.logger.info(f"æ–¹æ³•3: ä½¿ç”¨ç°¡å–®æŸ¥è©¢ç²å–åŸºæœ¬çµæ§‹...")
                try:
                    # ä½¿ç”¨bracketsä¾†è™•ç†ç‰¹æ®Šå­—ç¬¦
                    cursor.execute(f"SELECT TOP 1 * FROM [{schema}].[{table_name}]")
                    cursor.fetchone()  # æˆ‘å€‘ä¸é—œå¿ƒæ•¸æ“šï¼Œåªè¦æŸ¥è©¢çµæ§‹
                    
                    # å¾cursor.descriptionç²å–åŸºæœ¬æ¬„ä½ä¿¡æ¯
                    column_desc = cursor.description
                    columns = []
                    
                    for desc in column_desc:
                        col_name = desc[0]
                        # ç°¡åŒ–çš„é¡å‹æ˜ å°„
                        type_mapping = {
                            1: 'varchar',      # SQL_CHAR
                            4: 'int',          # SQL_INTEGER  
                            6: 'float',        # SQL_FLOAT
                            7: 'real',         # SQL_REAL
                            8: 'float',        # SQL_DOUBLE
                            12: 'varchar',     # SQL_VARCHAR
                            91: 'date',        # SQL_DATE
                            93: 'datetime',    # SQL_TIMESTAMP
                            -1: 'text',        # SQL_LONGVARCHAR
                            -7: 'bit'          # SQL_BIT
                        }
                        
                        data_type = type_mapping.get(desc[1], 'varchar')
                        max_length = desc[2] if desc[2] and desc[2] > 0 else None
                        
                        # æ¨¡æ“¬INFORMATION_SCHEMAçš„æ ¼å¼
                        col_info = (
                            col_name,           # COLUMN_NAME
                            data_type,          # DATA_TYPE
                            max_length,         # CHARACTER_MAXIMUM_LENGTH
                            desc[4],            # NUMERIC_PRECISION
                            desc[5],            # NUMERIC_SCALE
                            'YES' if desc[6] else 'NO',  # IS_NULLABLE
                            None                # COLUMN_DEFAULT
                        )
                        columns.append(col_info)
                    
                    self.logger.info(f"âœ… ä½¿ç”¨ç°¡å–®æŸ¥è©¢ç²å– {len(columns)} å€‹æ¬„ä½")
                    
                except Exception as e:
                    self.logger.error(f"ç°¡å–®æŸ¥è©¢ä¹Ÿå¤±æ•—: {e}")
                    columns = []
            
            # å¦‚æœé‚„æ˜¯æ²’æœ‰ç²å–åˆ°æ¬„ä½
            if not columns:
                self.logger.error(f"âŒ æ‰€æœ‰æ–¹æ³•éƒ½ç„¡æ³•ç²å–è¡¨æ ¼ {schema}.{table_name} çš„çµæ§‹")
                cursor.close()
                conn.close()
                return [], [], []
            
            # ç²å–ä¸»éµä¿¡æ¯
            self.logger.info(f"ç²å–ä¸»éµä¿¡æ¯...")
            try:
                cursor.execute(f"""
                    SELECT COLUMN_NAME
                    FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE
                    WHERE TABLE_NAME = ? 
                    AND TABLE_SCHEMA = ?
                    AND CONSTRAINT_NAME LIKE 'PK%'
                    ORDER BY ORDINAL_POSITION
                """, table_name, schema)
                primary_keys = [row[0] for row in cursor.fetchall()]
                
                if not primary_keys:
                    # å‚™ç”¨æ–¹æ³•ç²å–ä¸»éµ
                    cursor.execute(f"""
                        SELECT c.name
                        FROM sys.key_constraints k
                        INNER JOIN sys.index_columns ic ON k.parent_object_id = ic.object_id 
                            AND k.unique_index_id = ic.index_id
                        INNER JOIN sys.columns c ON ic.object_id = c.object_id 
                            AND ic.column_id = c.column_id
                        INNER JOIN sys.tables t ON k.parent_object_id = t.object_id
                        INNER JOIN sys.schemas s ON t.schema_id = s.schema_id
                        WHERE k.type = 'PK' AND t.name = ? AND s.name = ?
                        ORDER BY ic.key_ordinal
                    """, table_name, schema)
                    primary_keys = [row[0] for row in cursor.fetchall()]
                
                self.logger.info(f"æ‰¾åˆ° {len(primary_keys)} å€‹ä¸»éµ: {primary_keys}")
                
            except Exception as e:
                self.logger.warning(f"ç²å–ä¸»éµå¤±æ•—: {e}")
                primary_keys = []
            
            # ç²å–å¤–éµä¿¡æ¯
            self.logger.info(f"ç²å–å¤–éµä¿¡æ¯...")
            try:
                cursor.execute(f"""
                    SELECT 
                        KCU1.COLUMN_NAME,
                        KCU2.TABLE_NAME as REFERENCED_TABLE_NAME,
                        KCU2.COLUMN_NAME as REFERENCED_COLUMN_NAME
                    FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS RC
                    JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE KCU1
                        ON RC.CONSTRAINT_NAME = KCU1.CONSTRAINT_NAME
                    JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE KCU2
                        ON RC.UNIQUE_CONSTRAINT_NAME = KCU2.CONSTRAINT_NAME
                    WHERE KCU1.TABLE_NAME = ? 
                    AND KCU1.TABLE_SCHEMA = ?
                """, table_name, schema)
                foreign_keys = cursor.fetchall()
                self.logger.info(f"æ‰¾åˆ° {len(foreign_keys)} å€‹å¤–éµ")
                
            except Exception as e:
                self.logger.warning(f"ç²å–å¤–éµå¤±æ•—: {e}")
                foreign_keys = []
            
            cursor.close()
            conn.close()
            
            # é¡¯ç¤ºç²å–çµæœæ‘˜è¦
            self.logger.info(f"è¡¨æ ¼ {schema}.{table_name} çµæ§‹ç²å–å®Œæˆ:")
            self.logger.info(f"  - æ¬„ä½æ•¸: {len(columns)}")
            self.logger.info(f"  - ä¸»éµæ•¸: {len(primary_keys)}")
            self.logger.info(f"  - å¤–éµæ•¸: {len(foreign_keys)}")
            
            # é¡¯ç¤ºå‰å¹¾å€‹æ¬„ä½çš„è©³ç´°ä¿¡æ¯
            if columns:
                self.logger.info("å‰5å€‹æ¬„ä½:")
                for i, col in enumerate(columns[:5]):
                    self.logger.info(f"  {i+1}. {col[0]} ({col[1]})")
            
            return columns, primary_keys, foreign_keys
            
        except Exception as e:
            self.logger.error(f"ç²å–è¡¨æ ¼ {table_name} çµæ§‹æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {str(e)}")
            if conn:
                conn.close()
            return [], [], []
    
    def create_mssql_engine(self):
        """å‰µå»ºMSSQL SQLAlchemyå¼•æ“"""
        if self.mssql_engine:
            return self.mssql_engine
        
        try:
            server = self.mssql_config['server']
            database = self.mssql_config['database']
            
            if self.mssql_config.get('use_windows_auth', False):
                # Windowsé©—è­‰
                connection_url = URL.create(
                    "mssql+pyodbc",
                    host=server,
                    database=database,
                    query={
                        "driver": "ODBC Driver 17 for SQL Server",
                        "trusted_connection": "yes"
                    }
                )
            else:
                # SQL Serveré©—è­‰
                username = self.mssql_config.get('username', '')
                password = self.mssql_config.get('password', '')
                connection_url = URL.create(
                    "mssql+pyodbc",
                    username=username,
                    password=password,
                    host=server,
                    database=database,
                    query={
                        "driver": "ODBC Driver 17 for SQL Server"
                    }
                )
            
            self.mssql_engine = create_engine(connection_url, echo=False)
            
            # æ¸¬è©¦é€£æ¥
            with self.mssql_engine.connect() as conn:
                result = conn.execute(text("SELECT @@SERVERNAME, DB_NAME()"))
                server_info = result.fetchone()
                self.logger.info(f"âœ… SQLAlchemy MSSQLé€£æ¥æˆåŠŸ: {server_info[0]}, {server_info[1]}")
            
            return self.mssql_engine
            
        except Exception as e:
            self.logger.error(f"âŒ å‰µå»ºMSSQL SQLAlchemyå¼•æ“å¤±æ•—: {str(e)}")
            return None
        
    def convert_datatype(self, mssql_type: str, length: Optional[int], precision: Optional[int], scale: Optional[int]) -> str:
        """å°‡MSSQLè³‡æ–™é¡å‹è½‰æ›ç‚ºMariaDBé¡å‹ï¼ˆåŸºæ–¼æ¸¬è©¦æˆåŠŸçš„é‚è¼¯ï¼‰"""
        mssql_type_lower = mssql_type.lower()
        
        if mssql_type_lower in ['decimal', 'numeric']:
            if precision and scale is not None:
                return f'DECIMAL({precision},{scale})'
            else:
                return 'DECIMAL(10,2)'
        elif mssql_type_lower in ['varchar', 'nvarchar']:
            if length and length > 0:
                # MariaDB VARCHAR é™åˆ¶ï¼Œè¶…é16383è½‰ç‚ºTEXT
                if length > 16383:
                    return 'TEXT'
                return f'VARCHAR({length})'
            else:
                return 'TEXT'
        elif mssql_type_lower in ['char', 'nchar']:
            if length and length > 0:
                if length > 255:
                    return f'VARCHAR({length})'
                return f'CHAR({length})'
            else:
                return 'CHAR(1)'
        else:
            return self.datatype_mapping.get(mssql_type_lower, 'TEXT')
    
    def create_mariadb_table(self, table_name: str, columns: List, primary_keys: List, foreign_keys: List) -> bool:
        """åœ¨MariaDBä¸­å‰µå»ºè¡¨æ ¼ï¼ˆä¿®å¾©èªæ³•éŒ¯èª¤ä¸¦æ”¹é€²é‚è¼¯ï¼‰"""
        conn = self.connect_mariadb()
        if not conn:
            return False
        
        try:
            cursor = conn.cursor()
            
            # å…ˆåˆªé™¤è¡¨æ ¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰- ç¢ºä¿é‡æ–°å‰µå»º
            try:
                cursor.execute(f"DROP TABLE IF EXISTS `{table_name}`")
                self.logger.info(f"æ¸…ç†èˆŠè¡¨æ ¼: {table_name}")
            except:
                pass
            
            # æ§‹å»ºCREATE TABLEèªå¥
            col_definitions = []
            for col in columns:
                col_name = col[0]
                data_type = self.convert_datatype(col[1], col[2], col[3], col[4])
                nullable = "NULL" if col[5] == "YES" else "NOT NULL"
                
                col_def = f"`{col_name}` {data_type} {nullable}"
                col_definitions.append(col_def)
            
            # æ·»åŠ ä¸»éµ
            if primary_keys:
                pk_def = f"PRIMARY KEY ({', '.join([f'`{pk}`' for pk in primary_keys])})"
                col_definitions.append(pk_def)
            
            # ä¿®å¾©f-stringèªæ³•éŒ¯èª¤
            columns_sql = ',\n                '.join(col_definitions)
            create_sql = f"""CREATE TABLE `{table_name}` (
                {columns_sql}
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin"""
            
            cursor.execute(create_sql)
            conn.commit()
            
            # é©—è­‰å‰µå»ºæˆåŠŸ
            cursor.execute(f"DESCRIBE `{table_name}`")
            description = cursor.fetchall()
            self.logger.info(f"âœ… æˆåŠŸå‰µå»ºè¡¨æ ¼ {table_name}: {len(description)} å€‹æ¬„ä½")
            
            cursor.close()
            conn.close()
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ å‰µå»ºè¡¨æ ¼ {table_name} å¤±æ•—: {str(e)}")
            if conn:
                conn.close()
            return False
    
    def migrate_table_data(self, table_name: str, primary_keys: List) -> bool:
        """é·ç§»å–®å€‹è¡¨æ ¼çš„è³‡æ–™ - ä»¥è¡¨æ ¼ç‚ºå–®ä½commitç‰ˆæœ¬"""
        self.logger.info(f"é–‹å§‹é·ç§»è¡¨æ ¼: {table_name}")
        
        mssql_engine = self.create_mssql_engine()
        mariadb_conn = self.connect_mariadb()
        
        if not mssql_engine or not mariadb_conn:
            return False
        
        try:
            mariadb_cursor = mariadb_conn.cursor()
            
            # ç²å–ç¸½è¨˜éŒ„æ•¸
            count_query = text(f"SELECT COUNT(*) FROM [{table_name}]")
            with mssql_engine.connect() as conn:
                result = conn.execute(count_query)
                total_records = result.fetchone()[0]
            
            self.logger.info(f"è¡¨æ ¼ {table_name} ç¸½è¨˜éŒ„æ•¸: {total_records:,}")
            
            if total_records == 0:
                self.logger.info(f"è¡¨æ ¼ {table_name} ç„¡è³‡æ–™ï¼Œè·³éé·ç§»")
                mariadb_conn.close()
                return True
            
            # ğŸ”§ é—œéµï¼šåœ¨é–‹å§‹å‰è¨­ç½®è‡ªå‹•æäº¤ç‚ºFalseï¼Œæ•´å€‹è¡¨æ ¼ä½œç‚ºä¸€å€‹äº‹å‹™
            mariadb_conn.autocommit = False
            
            # åˆ†æ‰¹è™•ç†è®Šæ•¸
            offset = 0
            migrated_count = 0
            batch_number = 0
            start_time = time.time()
            
            # è™•ç†æ‰€æœ‰æ‰¹æ¬¡ï¼Œä½†ä¸æäº¤äº‹å‹™
            while offset < total_records:
                batch_number += 1
                
                try:
                    # æ§‹å»ºåˆ†é æŸ¥è©¢
                    if primary_keys:
                        order_clause = f"ORDER BY {', '.join([f'[{pk}]' for pk in primary_keys])}"
                    else:
                        order_clause = ""
                    
                    select_sql = f"""
                    SELECT * FROM [{table_name}] {order_clause}
                    OFFSET {offset} ROWS FETCH NEXT {self.batch_size} ROWS ONLY
                    """
                    
                    # å¾MSSQLç²å–æ•¸æ“š
                    df = pd.read_sql(select_sql, mssql_engine)
                    
                    if df.empty:
                        break
                    
                    # è³‡æ–™é è™•ç†
                    df = self.preprocess_data(df)
                    
                    # æ’å…¥MariaDBï¼ˆä¸æäº¤ï¼‰
                    success = self.insert_batch_to_mariadb(mariadb_cursor, table_name, df)
                    
                    if success:
                        migrated_count += len(df)
                        
                        # è¨˜éŒ„é€²åº¦ï¼ˆæ¯50å€‹æ‰¹æ¬¡æˆ–åˆ°é”æœ«å°¾æ™‚é¡¯ç¤ºï¼‰
                        if batch_number % 50 == 0 or offset + self.batch_size >= total_records:
                            elapsed_time = time.time() - start_time
                            progress = min((offset + self.batch_size) / total_records * 100, 100)
                            rate = migrated_count / elapsed_time if elapsed_time > 0 else 0
                            
                            self.logger.info(
                                f"æ‰¹æ¬¡ {batch_number}: å·²è™•ç† {migrated_count:,}/{total_records:,} ç­† "
                                f"({progress:.1f}%) - é€Ÿåº¦: {rate:.0f} ç­†/ç§’"
                            )
                            mariadb_conn.commit()
                    else:
                        # å¦‚æœä»»ä½•æ‰¹æ¬¡å¤±æ•—ï¼Œå›æ»¾æ•´å€‹è¡¨æ ¼
                        self.logger.error(f"âŒ æ‰¹æ¬¡ {batch_number} æ’å…¥å¤±æ•—ï¼Œå›æ»¾æ•´å€‹è¡¨æ ¼")
                        mariadb_conn.rollback()
                        mariadb_conn.close()
                        return False
                    
                    offset += self.batch_size
                    
                except Exception as e:
                    # æ‰¹æ¬¡è™•ç†ç•°å¸¸ï¼Œå›æ»¾æ•´å€‹è¡¨æ ¼
                    self.logger.error(f"âŒ æ‰¹æ¬¡ {batch_number} è™•ç†ç•°å¸¸: {str(e)}")
                    mariadb_conn.rollback()
                    mariadb_conn.close()
                    return False
            
            # ğŸ¯ é—œéµï¼šæ‰€æœ‰æ‰¹æ¬¡æˆåŠŸå¾Œï¼Œä¸€æ¬¡æ€§æäº¤æ•´å€‹è¡¨æ ¼
            self.logger.info(f"æ‰€æœ‰æ‰¹æ¬¡è™•ç†å®Œæˆï¼Œæäº¤è¡¨æ ¼ {table_name} çš„ {migrated_count:,} ç­†è³‡æ–™...")
            
            try:
                mariadb_conn.commit()
                total_time = time.time() - start_time
                avg_rate = migrated_count / total_time if total_time > 0 else 0
                
                self.logger.info(f"âœ… è¡¨æ ¼ {table_name} é·ç§»æˆåŠŸå®Œæˆ:")
                self.logger.info(f"  - ç¸½è¨˜éŒ„æ•¸: {total_records:,}")
                self.logger.info(f"  - æˆåŠŸé·ç§»: {migrated_count:,}")
                self.logger.info(f"  - è™•ç†æ™‚é–“: {total_time:.1f} ç§’")
                self.logger.info(f"  - å¹³å‡é€Ÿåº¦: {avg_rate:.0f} ç­†/ç§’")
                self.logger.info(f"  - æˆåŠŸç‡: 100.00%")
                
            except Exception as commit_error:
                self.logger.error(f"âŒ æäº¤äº‹å‹™å¤±æ•—: {str(commit_error)}")
                mariadb_conn.rollback()
                mariadb_conn.close()
                return False
            
            mariadb_conn.close()
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ é·ç§»è¡¨æ ¼ {table_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            if mariadb_conn:
                try:
                    mariadb_conn.rollback()
                except:
                    pass
                mariadb_conn.close()
            return False
    
    def insert_batch_to_mariadb(self, cursor, table_name: str, df: pd.DataFrame) -> bool:
        """æ‰¹æ¬¡æ’å…¥è³‡æ–™åˆ°MariaDBï¼ˆé…åˆè¡¨æ ¼ç´šcommitï¼‰"""
        if df.empty:
            return True
        
        try:
            # æ§‹å»ºINSERTèªå¥
            columns = [f"`{col}`" for col in df.columns]
            placeholders = ', '.join(['%s'] * len(df.columns))
            
            insert_sql = f"INSERT INTO `{table_name}` ({', '.join(columns)}) VALUES ({placeholders})"
            
            # æº–å‚™æ•¸æ“šï¼Œé—œéµï¼šè™•ç†numpyé¡å‹è½‰æ›
            data_tuples = []
            for _, row in df.iterrows():
                processed_row = []
                for value in row.values:
                    if value is None or pd.isna(value):
                        processed_row.append(None)
                    elif isinstance(value, str):
                        # è™•ç†å­—ç¬¦ä¸²ï¼Œä¿æŒæ•¸æ“šå®Œæ•´æ€§
                        processed_row.append(value)
                    else:
                        # ğŸ”§ é—œéµä¿®å¾©ï¼šå°‡numpyé¡å‹è½‰æ›ç‚ºPythonåŸç”Ÿé¡å‹
                        processed_row.append(self.convert_numpy_to_python(value))
                
                data_tuples.append(tuple(processed_row))
            
            # æ ¹æ“šæ•¸æ“šé‡é¸æ“‡æ’å…¥æ–¹å¼
            if len(data_tuples) == 1:
                # å–®ç­†æ’å…¥
                cursor.execute(insert_sql, data_tuples[0])
            elif len(data_tuples) <= 100:
                # å°æ‰¹æ¬¡ï¼šä½¿ç”¨executemany
                cursor.executemany(insert_sql, data_tuples)
            else:
                # å¤§æ‰¹æ¬¡ï¼šåˆ†æ®µexecutemanyï¼Œé¿å…å…§å­˜å•é¡Œ
                chunk_size = 100
                for i in range(0, len(data_tuples), chunk_size):
                    chunk = data_tuples[i:i + chunk_size]
                    cursor.executemany(insert_sql, chunk)
            
            return True
            
        except mysql.connector.Error as e:
            self.logger.error(f"âŒ MariaDBæ’å…¥å¤±æ•—:")
            self.logger.error(f"   éŒ¯èª¤ç¢¼: {e.errno}")
            self.logger.error(f"   éŒ¯èª¤è¨Šæ¯: {e.msg}")
            
            # è©³ç´°éŒ¯èª¤åˆ†æ
            if e.errno == 1062:  # Duplicate entry
                self.logger.error("   â†’ ä¸»éµé‡è¤‡ï¼Œå¯èƒ½éœ€è¦æ¸…ç†ç›®æ¨™è¡¨æ ¼")
            elif e.errno == 1406:  # Data too long
                self.logger.error("   â†’ è³‡æ–™é•·åº¦è¶…éæ¬„ä½é™åˆ¶")
            elif e.errno == 1264:  # Out of range
                self.logger.error("   â†’ æ•¸å€¼è¶…å‡ºç¯„åœ")
            
            return False
            
        except Exception as e:
            self.logger.error(f"âŒ æ’å…¥éç¨‹ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {str(e)}")
            import traceback
            self.logger.error(f"   è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            return False
        
    def batch_insert_remaining(self, cursor, table_name: str, df: pd.DataFrame, insert_sql: str) -> bool:
        """æ‰¹æ¬¡æ’å…¥å‰©é¤˜è³‡æ–™"""
        try:
            # æº–å‚™å‰©é¤˜è³‡æ–™
            data_tuples = []
            for _, row in df.iterrows():
                processed_row = []
                for value in row.values:
                    if value is None or pd.isna(value):
                        processed_row.append(None)
                    elif isinstance(value, str):
                        processed_row.append(value) # strip
                    else:
                        processed_row.append(value)
                
                data_tuples.append(tuple(processed_row))
            
            # åŸ·è¡Œæ‰¹æ¬¡æ’å…¥
            cursor.executemany(insert_sql, data_tuples)
            self.logger.info(f"âœ… æ‰¹æ¬¡æ’å…¥å‰©é¤˜ {len(data_tuples)} ç­†æˆåŠŸ")
            return True
            
        except mysql.connector.Error as e:
            self.logger.error(f"âŒ æ‰¹æ¬¡æ’å…¥å‰©é¤˜è³‡æ–™å¤±æ•—:")
            self.logger.error(f"   éŒ¯èª¤ç¢¼: {e.errno}")
            self.logger.error(f"   éŒ¯èª¤è¨Šæ¯: {e.msg}")
            
            # å¦‚æœæ‰¹æ¬¡æ’å…¥å¤±æ•—ï¼Œæ”¹ç‚ºé€ç­†æ’å…¥ä»¥æ‰¾å‡ºå•é¡Œè³‡æ–™
            return self.fallback_single_insert(cursor, df, insert_sql)
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰¹æ¬¡æ’å…¥ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {str(e)}")
            return False

    def fallback_single_insert(self, cursor, df: pd.DataFrame, insert_sql: str) -> bool:
        """å‚™ç”¨æ–¹æ¡ˆï¼šé€ç­†æ’å…¥"""
        self.logger.info("ğŸ”„ æ‰¹æ¬¡æ’å…¥å¤±æ•—ï¼Œæ”¹ç‚ºé€ç­†æ’å…¥è¨ºæ–·...")
        
        success_count = 0
        error_count = 0
        
        for index, row in df.iterrows():
            try:
                processed_row = []
                for value in row.values:
                    if value is None or pd.isna(value):
                        processed_row.append(None)
                    elif isinstance(value, str):
                        processed_row.append(value) #.strip()
                    else:
                        processed_row.append(value)
                
                cursor.execute(insert_sql, tuple(processed_row))
                success_count += 1
                
                if success_count % 100 == 0:
                    self.logger.info(f"   å·²æˆåŠŸæ’å…¥ {success_count} ç­†...")
                
            except mysql.connector.Error as e:
                error_count += 1
                if error_count <= 5:  # åªè¨˜éŒ„å‰5å€‹éŒ¯èª¤
                    self.logger.error(f"âŒ ç¬¬ {index+1} ç­†æ’å…¥å¤±æ•—:")
                    self.logger.error(f"   éŒ¯èª¤: {e.msg}")
                    
                    # è¨˜éŒ„å•é¡Œè³‡æ–™çš„å‰å¹¾å€‹æ¬„ä½
                    problem_data = {}
                    for col, val in zip(df.columns, row.values):
                        if isinstance(val, str) and len(val) > 50:
                            problem_data[col] = f"{val[:47]}..."
                        else:
                            problem_data[col] = val
                    self.logger.error(f"   è³‡æ–™: {problem_data}")
                
                if error_count > 10:  # å¦‚æœéŒ¯èª¤å¤ªå¤šï¼Œåœæ­¢
                    self.logger.error(f"âŒ éŒ¯èª¤éå¤š ({error_count})ï¼Œåœæ­¢æ’å…¥")
                    break
        
        self.logger.info(f"ğŸ“Š é€ç­†æ’å…¥çµæœ: æˆåŠŸ {success_count}, å¤±æ•— {error_count}")
        return error_count == 0

    def analyze_insert_error(self, error, row_data, columns, table_name):
        """åˆ†ææ’å…¥éŒ¯èª¤"""
        self.logger.error("ğŸ” éŒ¯èª¤åˆ†æ:")
        
        # å¸¸è¦‹éŒ¯èª¤åˆ†æ
        if hasattr(error, 'errno'):
            if error.errno == 1062:  # Duplicate entry
                self.logger.error("   â†’ ä¸»éµé‡è¤‡éŒ¯èª¤")
                # æ‰¾å‡ºä¸»éµæ¬„ä½çš„å€¼
                for col, val in zip(columns, row_data.values):
                    if 'id' in col.lower() or 'name' in col.lower():
                        self.logger.error(f"   â†’ å¯èƒ½çš„é‡è¤‡å€¼: {col} = {val}")
                        
            elif error.errno == 1406:  # Data too long
                self.logger.error("   â†’ è³‡æ–™é•·åº¦è¶…éæ¬„ä½é™åˆ¶")
                for col, val in zip(columns, row_data.values):
                    if isinstance(val, str) and len(val) > 255:
                        self.logger.error(f"   â†’ éé•·æ¬„ä½: {col} (é•·åº¦: {len(val)})")
                        
            elif error.errno == 1264:  # Out of range
                self.logger.error("   â†’ æ•¸å€¼è¶…å‡ºç¯„åœ")
                for col, val in zip(columns, row_data.values):
                    if isinstance(val, (int, float)) and abs(val) > 2147483647:
                        self.logger.error(f"   â†’ éå¤§æ•¸å€¼: {col} = {val}")
                        
            elif error.errno == 1292:  # Incorrect value
                self.logger.error("   â†’ è³‡æ–™æ ¼å¼éŒ¯èª¤")
                for col, val in zip(columns, row_data.values):
                    if 'date' in col.lower() or 'time' in col.lower():
                        self.logger.error(f"   â†’ å¯èƒ½çš„æ—¥æœŸå•é¡Œ: {col} = {val}")
        
        # æª¢æŸ¥è¡¨æ ¼çµæ§‹æ˜¯å¦åŒ¹é…
        self.logger.error("ğŸ” å»ºè­°æª¢æŸ¥:")
        self.logger.error("   1. MariaDBè¡¨æ ¼çµæ§‹æ˜¯å¦æ­£ç¢ºå‰µå»º")
        self.logger.error("   2. æ¬„ä½é•·åº¦æ˜¯å¦è¶³å¤ ")
        self.logger.error("   3. è³‡æ–™é¡å‹æ˜¯å¦åŒ¹é…")
        self.logger.error("   4. å­—ç¬¦ç·¨ç¢¼æ˜¯å¦ä¸€è‡´")
    
    def validate_batch_data(self, table_name: str, df: pd.DataFrame, primary_keys: List) -> bool:
        """é©—è­‰æ‰¹æ¬¡è³‡æ–™ä¸€è‡´æ€§"""
        if df.empty or not primary_keys:
            return True
        
        try:
            mariadb_conn = self.connect_mariadb()
            if not mariadb_conn:
                return False
            
            cursor = mariadb_conn.cursor()
            
            # æª¢æŸ¥ç¬¬ä¸€ç­†å’Œæœ€å¾Œä¸€ç­†è¨˜éŒ„
            for idx in [0, len(df) - 1]:
                if idx < len(df):
                    # æ§‹å»ºWHEREæ¢ä»¶
                    where_conditions = []
                    params = []
                    for pk in primary_keys:
                        if pk in df.columns:
                            where_conditions.append(f"`{pk}` = %s")
                            params.append(df.iloc[idx][pk])
                    
                    if where_conditions:
                        where_clause = " AND ".join(where_conditions)
                        check_sql = f"SELECT COUNT(*) FROM `{table_name}` WHERE {where_clause}"
                        cursor.execute(check_sql, params)
                        count = cursor.fetchone()[0]
                        
                        if count == 0:
                            cursor.close()
                            mariadb_conn.close()
                            return False
            
            cursor.close()
            mariadb_conn.close()
            return True
            
        except Exception as e:
            self.logger.error(f"æ‰¹æ¬¡é©—è­‰å¤±æ•—: {str(e)}")
            return False
    
    def log_batch_error(self, table_name: str, batch_number: int, error_message: str):
        """è¨˜éŒ„æ‰¹æ¬¡éŒ¯èª¤"""
        error_log = {
            'timestamp': datetime.now().isoformat(),
            'table_name': table_name,
            'batch_number': batch_number,
            'error_message': error_message
        }
        
        self.migration_log.append(error_log)
        
        # å¯«å…¥éŒ¯èª¤æ—¥èªŒæª”æ¡ˆ
        error_file = f'migration_logs/batch_errors_{datetime.now().strftime("%Y%m%d")}.json'
        with open(error_file, 'w', encoding='utf-8') as f:
            json.dump(self.migration_log, f, ensure_ascii=False, indent=2)
    
    def validate_migration_complete(self, schema: str = 'dbo') -> Dict[str, Any]:

        """å®Œæ•´çš„é·ç§»å¾Œé©—è­‰"""
        self.logger.info("é–‹å§‹é€²è¡Œé·ç§»å¾Œå®Œæ•´é©—è­‰...")
        
        tables = self.get_mssql_tables(schema)
        validation_results = {
            'timestamp': datetime.now().isoformat(),
            'tables': {},
            'overall_success': True
        }
        
        for table_name in tables:
            if table_name == "Memo":
                validation_results['tables'][table_name] = {
                    'record_count_match': True,
                    'mssql_count': 0,
                    'mariadb_count': 0,
                    'sample_data_match': True,
                    'extreme_values_match': True,
                    'data_consistency': True
                }
                continue

            self.logger.info(f"é©—è­‰è¡¨æ ¼: {table_name}")
            table_result = self.validate_single_table(table_name)
            validation_results['tables'][table_name] = table_result
            
            if not table_result['data_consistency']:
                validation_results['overall_success'] = False
        
        # ç”Ÿæˆé©—è­‰å ±å‘Š
        self.generate_validation_report(validation_results)
        
        return validation_results
    
    def validate_single_table(self, table_name: str) -> Dict[str, Any]:
        """é©—è­‰å–®å€‹è¡¨æ ¼çš„ä¸€è‡´æ€§"""
        result = {
            'record_count_match': False,
            'mssql_count': 0,
            'mariadb_count': 0,
            'sample_data_match': False,
            'extreme_values_match': False,
            'data_consistency': False
        }
        
        try:
            mssql_conn = self.connect_mssql()
            mariadb_conn = self.connect_mariadb()
            
            if not mssql_conn or not mariadb_conn:
                return result
            
            # 1. è¨˜éŒ„æ•¸æ¯”è¼ƒ
            mssql_cursor = mssql_conn.cursor()
            mariadb_cursor = mariadb_conn.cursor()
            
            mssql_cursor.execute(f"SELECT COUNT(*) FROM [{table_name}]")
            result['mssql_count'] = mssql_cursor.fetchone()[0]
            
            mariadb_cursor.execute(f"SELECT COUNT(*) FROM `{table_name}`")
            result['mariadb_count'] = mariadb_cursor.fetchone()[0]
            
            result['record_count_match'] = result['mssql_count'] == result['mariadb_count']
            
            # 2. æŠ½æ¨£è³‡æ–™æ¯”è¼ƒï¼ˆåƒ…åœ¨è¨˜éŒ„æ•¸åŒ¹é…æ™‚é€²è¡Œï¼‰
            if result['record_count_match'] and result['mssql_count'] > 0:
                result['sample_data_match'] = self.validate_sample_data(table_name, mssql_cursor, mariadb_cursor)
                result['extreme_values_match'] = self.validate_extreme_values(table_name, mssql_cursor, mariadb_cursor)
            
            # 3. ç¶œåˆåˆ¤æ–·
            result['data_consistency'] = (
                result['record_count_match'] and 
                result['sample_data_match'] and 
                result['extreme_values_match']
            )
            
            mssql_conn.close()
            mariadb_conn.close()
            
        except Exception as e:
            self.logger.error(f"é©—è­‰è¡¨æ ¼ {table_name} å¤±æ•—: {str(e)}")
        
        return result
    
    def validate_sample_data(self, table_name: str, mssql_cursor, mariadb_cursor, sample_size: int = 100) -> bool:
        """æŠ½æ¨£é©—è­‰è³‡æ–™ä¸€è‡´æ€§"""
        try:
            # éš¨æ©ŸæŠ½å–æ¨£æœ¬é€²è¡Œæ¯”è¼ƒ
            mssql_cursor.execute(f"SELECT TOP {sample_size} * FROM [{table_name}] ORDER BY NEWID()")
            mssql_sample = mssql_cursor.fetchall()
            
            if not mssql_sample:
                return True
            
            # ç²å–åˆ—å
            columns = [desc[0] for desc in mssql_cursor.description]
            
            # å¾MariaDBç²å–å°æ‡‰è³‡æ–™ï¼ˆç°¡åŒ–æ¯”è¼ƒï¼‰
            mariadb_cursor.execute(f"SELECT * FROM `{table_name}` LIMIT {sample_size}")
            mariadb_sample = mariadb_cursor.fetchall()
            
            return len(mssql_sample) == len(mariadb_sample)
            
        except Exception as e:
            self.logger.error(f"æŠ½æ¨£é©—è­‰å¤±æ•—: {str(e)}")
            return False
    
    def validate_extreme_values(self, table_name: str, mssql_cursor, mariadb_cursor) -> bool:
        """é©—è­‰æ¥µå€¼ä¸€è‡´æ€§"""
        try:
            # ç²å–æ•¸å€¼åˆ—
            mssql_cursor.execute(f"""
                SELECT COLUMN_NAME, DATA_TYPE 
                FROM INFORMATION_SCHEMA.COLUMNS 
                WHERE TABLE_NAME = '{table_name}' 
                AND DATA_TYPE IN ('int', 'bigint', 'decimal', 'numeric', 'float', 'real', 'money')
            """)
            numeric_columns = mssql_cursor.fetchall()
            
            for col_name, data_type in numeric_columns:
                # MSSQLæ¥µå€¼
                mssql_cursor.execute(f"SELECT MIN([{col_name}]), MAX([{col_name}]) FROM [{table_name}] WHERE [{col_name}] IS NOT NULL")
                mssql_extremes = mssql_cursor.fetchone()
                
                # MariaDBæ¥µå€¼
                mariadb_cursor.execute(f"SELECT MIN(`{col_name}`), MAX(`{col_name}`) FROM `{table_name}` WHERE `{col_name}` IS NOT NULL")
                mariadb_extremes = mariadb_cursor.fetchone()
                
                if mssql_extremes and mariadb_extremes:
                    if mssql_extremes[0] != mariadb_extremes[0] or mssql_extremes[1] != mariadb_extremes[1]:
                        self.logger.warning(f"è¡¨æ ¼ {table_name} åˆ— {col_name} æ¥µå€¼ä¸åŒ¹é…")
                        return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ¥µå€¼é©—è­‰å¤±æ•—: {str(e)}")
            return False
    
    def generate_validation_report(self, validation_results: Dict):
        """ç”Ÿæˆé©—è­‰å ±å‘Š"""
        report_file = f'migration_logs/validation_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.html'
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>è³‡æ–™åº«é·ç§»é©—è­‰å ±å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background-color: #f0f0f0; padding: 15px; border-radius: 5px; }}
                .success {{ color: green; font-weight: bold; }}
                .error {{ color: red; font-weight: bold; }}
                .warning {{ color: orange; font-weight: bold; }}
                table {{ border-collapse: collapse; width: 100%; margin-top: 20px; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
                .status-ok {{ background-color: #d4edda; }}
                .status-error {{ background-color: #f8d7da; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>è³‡æ–™åº«é·ç§»é©—è­‰å ±å‘Š</h1>
                <p><strong>é©—è­‰æ™‚é–“:</strong> {validation_results['timestamp']}</p>
                <p><strong>æ•´é«”çµæœ:</strong> 
                    <span class="{'success' if validation_results['overall_success'] else 'error'}">
                        {'æˆåŠŸ' if validation_results['overall_success'] else 'å¤±æ•—'}
                    </span>
                </p>
            </div>
            
            <h2>è¡¨æ ¼è©³ç´°é©—è­‰çµæœ</h2>
            <table>
                <tr>
                    <th>è¡¨æ ¼åç¨±</th>
                    <th>MSSQLè¨˜éŒ„æ•¸</th>
                    <th>MariaDBè¨˜éŒ„æ•¸</th>
                    <th>è¨˜éŒ„æ•¸åŒ¹é…</th>
                    <th>æŠ½æ¨£é©—è­‰</th>
                    <th>æ¥µå€¼é©—è­‰</th>
                    <th>æ•´é«”ä¸€è‡´æ€§</th>
                </tr>
        """
        
        for table_name, result in validation_results['tables'].items():
            consistency_class = "status-ok" if result['data_consistency'] else "status-error"
            html_content += f"""
                <tr class="{consistency_class}">
                    <td>{table_name}</td>
                    <td>{result['mssql_count']:,}</td>
                    <td>{result['mariadb_count']:,}</td>
                    <td>{'âœ“' if result['record_count_match'] else 'âœ—'}</td>
                    <td>{'âœ“' if result['sample_data_match'] else 'âœ—'}</td>
                    <td>{'âœ“' if result['extreme_values_match'] else 'âœ—'}</td>
                    <td>{'âœ“' if result['data_consistency'] else 'âœ—'}</td>
                </tr>
            """
        
        html_content += """
            </table>
            
            <h2>èªªæ˜</h2>
            <ul>
                <li><strong>è¨˜éŒ„æ•¸åŒ¹é…:</strong> æª¢æŸ¥ä¾†æºå’Œç›®æ¨™è³‡æ–™åº«çš„è¨˜éŒ„ç¸½æ•¸æ˜¯å¦ç›¸åŒ</li>
                <li><strong>æŠ½æ¨£é©—è­‰:</strong> éš¨æ©ŸæŠ½å–æ¨£æœ¬è³‡æ–™é€²è¡Œæ¯”è¼ƒ</li>
                <li><strong>æ¥µå€¼é©—è­‰:</strong> æª¢æŸ¥æ•¸å€¼åˆ—çš„æœ€å¤§å€¼å’Œæœ€å°å€¼æ˜¯å¦ä¸€è‡´</li>
                <li><strong>æ•´é«”ä¸€è‡´æ€§:</strong> ç¶œåˆæ‰€æœ‰é©—è­‰é …ç›®çš„çµæœ</li>
            </ul>
        </body>
        </html>
        """
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        self.logger.info(f"é©—è­‰å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    def migrate_full_database(self, schema: str = 'dbo') -> bool:
        """åŸ·è¡Œå®Œæ•´è³‡æ–™åº«é·ç§»ï¼ˆé…åˆè¡¨æ ¼ç´šcommitï¼‰"""
        self.logger.info("é–‹å§‹å®Œæ•´è³‡æ–™åº«é·ç§»...")
        
        # å®šç¾©è¡¨æ ¼é·ç§»é †åº (GPTè‡ªè¡Œåˆ†æ)
        table_order = [
            'CompanyOwner',
            'Factory', 
            'Announcement',
            'ViolationCase',
            'Memo',
            'AllowRework',
            'Appeal',
            'IllegalProfit',
            'Inspection',
            'Detail'
        ]
        
        # ç²å–æ‰€æœ‰è¡¨æ ¼
        all_tables = self.get_mssql_tables(schema)
        if not all_tables:
            self.logger.error("âŒ ç„¡æ³•ç²å–MSSQLè¡¨æ ¼åˆ—è¡¨")
            return False
        
        # ç¬¬ä¸€éšæ®µï¼šå‰µå»ºæ‰€æœ‰è¡¨æ ¼çµæ§‹
        self.logger.info("ğŸ”§ ç¬¬ä¸€éšæ®µï¼šå‰µå»ºè¡¨æ ¼çµæ§‹...")
        structure_success_count = 0
        
        for table_name in table_order:
            if table_name in all_tables:
                self.logger.info(f"å‰µå»ºè¡¨æ ¼çµæ§‹: {table_name}")
                
                columns, primary_keys, foreign_keys = self.get_table_schema(table_name, schema)
                
                if not columns:
                    self.logger.error(f"âŒ ç„¡æ³•ç²å–è¡¨æ ¼ {table_name} çš„çµæ§‹")
                    continue
                
                if self.create_mariadb_table(table_name, columns, primary_keys, foreign_keys):
                    structure_success_count += 1
                    self.logger.info(f"âœ… è¡¨æ ¼ {table_name} çµæ§‹å‰µå»ºæˆåŠŸ")
                else:
                    self.logger.error(f"âŒ è¡¨æ ¼ {table_name} çµæ§‹å‰µå»ºå¤±æ•—")
        
        if structure_success_count == 0:
            self.logger.error("âŒ æ²’æœ‰ä»»ä½•è¡¨æ ¼çµæ§‹å‰µå»ºæˆåŠŸï¼Œçµ‚æ­¢é·ç§»")
            return False
        
        self.logger.info(f"âœ… è¡¨æ ¼çµæ§‹å‰µå»ºå®Œæˆ: {structure_success_count}/{len(table_order)}")
        
        # ç¬¬äºŒéšæ®µï¼šä»¥è¡¨æ ¼ç‚ºå–®ä½é·ç§»è³‡æ–™
        self.logger.info("ğŸ“Š ç¬¬äºŒéšæ®µï¼šé·ç§»è³‡æ–™ï¼ˆä»¥è¡¨æ ¼ç‚ºå–®ä½commitï¼‰...")
        data_success_count = 0
        failed_tables = []
        
        for table_name in table_order:
            if table_name in all_tables:
                self.logger.info(f"\nğŸš€ é–‹å§‹é·ç§»è¡¨æ ¼: {table_name}")
                
                # ç²å–ä¸»éµ
                _, primary_keys, _ = self.get_table_schema(table_name, schema)
                
                # é·ç§»æ•´å€‹è¡¨æ ¼ï¼ˆä½œç‚ºä¸€å€‹äº‹å‹™ï¼‰
                if self.migrate_table_data(table_name, primary_keys):
                    data_success_count += 1
                    self.logger.info(f"âœ… è¡¨æ ¼ {table_name} å®Œæ•´é·ç§»æˆåŠŸ\n")
                else:
                    failed_tables.append(table_name)
                    self.logger.error(f"âŒ è¡¨æ ¼ {table_name} é·ç§»å¤±æ•—\n")
        
        # è™•ç†å‰©é¤˜è¡¨æ ¼
        remaining_tables = [t for t in all_tables if t not in table_order]
        for table_name in remaining_tables:
            self.logger.info(f"\nğŸš€ è™•ç†é¡å¤–è¡¨æ ¼: {table_name}")
            
            columns, primary_keys, foreign_keys = self.get_table_schema(table_name, schema)
            if columns:
                if self.create_mariadb_table(table_name, columns, primary_keys, foreign_keys):
                    structure_success_count += 1
                    
                    if self.migrate_table_data(table_name, primary_keys):
                        data_success_count += 1
                        self.logger.info(f"âœ… é¡å¤–è¡¨æ ¼ {table_name} å®Œæ•´é·ç§»æˆåŠŸ")
                    else:
                        failed_tables.append(table_name)
                        self.logger.error(f"âŒ é¡å¤–è¡¨æ ¼ {table_name} é·ç§»å¤±æ•—")
        
        # ç¬¬ä¸‰éšæ®µï¼šé©—è­‰é·ç§»çµæœ
        self.logger.info("ğŸ” ç¬¬ä¸‰éšæ®µï¼šé©—è­‰é·ç§»çµæœ...")
        existing_tables = self.check_mariadb_tables_exist()
        
        # ç”Ÿæˆè©³ç´°å ±å‘Š
        self.logger.info(f"\nğŸ“Š é·ç§»çµæœç¸½çµ:")
        self.logger.info(f"  - ç›®æ¨™è¡¨æ ¼æ•¸: {len(all_tables)}")
        self.logger.info(f"  - çµæ§‹å‰µå»ºæˆåŠŸ: {structure_success_count}")
        self.logger.info(f"  - è³‡æ–™é·ç§»æˆåŠŸ: {data_success_count}")
        self.logger.info(f"  - MariaDBç¾æœ‰è¡¨æ ¼: {len(existing_tables)}")
        
        if failed_tables:
            self.logger.warning(f"  - å¤±æ•—è¡¨æ ¼: {', '.join(failed_tables)}")
        
        if data_success_count == len(all_tables):
            self.logger.info("ğŸ‰ æ‰€æœ‰è¡¨æ ¼é·ç§»æˆåŠŸï¼")
        elif data_success_count > 0:
            self.logger.warning(f"âš ï¸  éƒ¨åˆ†è¡¨æ ¼é·ç§»æˆåŠŸ ({data_success_count}/{len(all_tables)})")
        else:
            self.logger.error("âŒ æ²’æœ‰ä»»ä½•è¡¨æ ¼æˆåŠŸé·ç§»")
        
        return data_success_count > 0
    
    def check_mariadb_tables_exist(self) -> List[str]:
        """æª¢æŸ¥MariaDBä¸­å­˜åœ¨çš„è¡¨æ ¼"""
        conn = self.connect_mariadb()
        if not conn:
            return []
        
        try:
            cursor = conn.cursor()
            cursor.execute("SHOW TABLES")
            tables = [row[0] for row in cursor.fetchall()]
            cursor.close()
            conn.close()
            return tables
        except Exception as e:
            self.logger.error(f"æª¢æŸ¥MariaDBè¡¨æ ¼å¤±æ•—: {str(e)}")
            return []
    
    def optimize_mariadb_tables(self):
        """å°MariaDBè¡¨æ ¼é€²è¡Œå„ªåŒ–ï¼ˆå¿«é€Ÿä¿®å¾©ç‰ˆæœ¬ï¼‰"""
        self.logger.info("é–‹å§‹å„ªåŒ–MariaDBè¡¨æ ¼...")
        
        conn = self.connect_mariadb()
        if not conn:
            return
        
        try:
            optimization_results = {}
            
            # ç²å–æ‰€æœ‰è¡¨æ ¼
            cursor = conn.cursor()
            cursor.execute("SHOW TABLES")
            tables = [row[0] for row in cursor.fetchall()]
            cursor.close()
            
            for table_name in tables:
                self.logger.info(f"å„ªåŒ–è¡¨æ ¼: {table_name}")
                
                try:
                    # ç‚ºæ¯å€‹è¡¨æ ¼ä½¿ç”¨æ–°çš„ cursor
                    table_cursor = conn.cursor()
                    
                    # åˆ†æè¡¨æ ¼
                    table_cursor.execute(f"ANALYZE TABLE `{table_name}`")
                    analyze_result = table_cursor.fetchall()
                    
                    # å„ªåŒ–è¡¨æ ¼
                    table_cursor.execute(f"OPTIMIZE TABLE `{table_name}`")
                    optimize_result = table_cursor.fetchall()
                    
                    # ç²å–è¨˜éŒ„æ•¸
                    table_cursor.execute(f"SELECT COUNT(*) FROM `{table_name}`")
                    row_count = table_cursor.fetchone()[0]
                    
                    table_cursor.close()
                    
                    optimization_results[table_name] = {
                        'status': 'optimized',
                        'analyze_result': analyze_result,
                        'optimize_result': optimize_result,
                        'row_count': row_count
                    }
                    
                    self.logger.info(f"âœ… è¡¨æ ¼ {table_name} å„ªåŒ–å®Œæˆ - è¨˜éŒ„æ•¸: {row_count:,}")
                    
                except Exception as e:
                    self.logger.error(f"âŒ è¡¨æ ¼ {table_name} å„ªåŒ–å¤±æ•—: {str(e)}")
                    optimization_results[table_name] = {
                        'status': 'error',
                        'error': str(e)
                    }
            
            # ç”Ÿæˆå„ªåŒ–å ±å‘Š
            self.generate_optimization_report(optimization_results)
            
            conn.close()
            
            # é¡¯ç¤ºæ‘˜è¦
            successful = sum(1 for r in optimization_results.values() if r['status'] == 'optimized')
            self.logger.info(f"âœ… å„ªåŒ–å®Œæˆ: {successful}/{len(tables)} å€‹è¡¨æ ¼æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"å„ªåŒ–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            if conn:
                conn.close()
    
    def clean_mariadb_tables(self):
        """æ¸…ç†MariaDBä¸­çš„æ‰€æœ‰ç›¸é—œè¡¨æ ¼"""
        self.logger.info("é–‹å§‹æ¸…ç†MariaDBè¡¨æ ¼...")
        
        conn = self.connect_mariadb()
        if not conn:
            return False
        
        try:
            cursor = conn.cursor()
            
            # ç²å–æ‰€æœ‰è¡¨æ ¼
            cursor.execute("SHOW TABLES")
            tables = [row[0] for row in cursor.fetchall()]
            
            # é å®šç¾©çš„è¡¨æ ¼é †åºï¼ˆåå‘åˆªé™¤ï¼Œé¿å…å¤–éµç´„æŸå•é¡Œï¼‰
            target_tables = [
                'Detail', 'Inspection', 'IllegalProfit', 'Appeal', 
                'AllowRework', 'Memo', 'ViolationCase', 
                'Announcement', 'Factory', 'CompanyOwner'
            ]
            
            # å…ˆç¦ç”¨å¤–éµæª¢æŸ¥
            cursor.execute("SET FOREIGN_KEY_CHECKS = 0")
            
            cleaned_count = 0
            for table in target_tables:
                # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨ï¼ˆä¸å€åˆ†å¤§å°å¯«ï¼‰
                table_exists = any(t.lower() == table.lower() for t in tables)
                
                if table_exists:
                    try:
                        cursor.execute(f"DROP TABLE IF EXISTS `{table}`")
                        self.logger.info(f"ğŸ—‘ï¸  å·²åˆªé™¤è¡¨æ ¼: {table}")
                        cleaned_count += 1
                    except Exception as e:
                        self.logger.warning(f"âš ï¸  ç„¡æ³•åˆªé™¤è¡¨æ ¼ {table}: {e}")
            
            # é‡æ–°å•Ÿç”¨å¤–éµæª¢æŸ¥
            cursor.execute("SET FOREIGN_KEY_CHECKS = 1")
            
            conn.commit()
            cursor.close()
            conn.close()
            
            self.logger.info(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±åˆªé™¤ {cleaned_count} å€‹è¡¨æ ¼")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç†è¡¨æ ¼å¤±æ•—: {str(e)}")
            if conn:
                conn.close()
            return False
    
    def generate_optimization_report(self, results: Dict):
        """ç”Ÿæˆå„ªåŒ–å ±å‘Š"""
        report_file = f'migration_logs/optimization_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("MariaDB è¡¨æ ¼å„ªåŒ–å ±å‘Š\n")
            f.write("=" * 50 + "\n")
            f.write(f"å„ªåŒ–æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            for table_name, result in results.items():
                f.write(f"è¡¨æ ¼: {table_name}\n")
                f.write(f"ç‹€æ…‹: {result['status']}\n")
                if 'explain_info' in result:
                    f.write("EXPLAIN åˆ†æçµæœ:\n")
                    for row in result['explain_info']:
                        f.write(f"  {row}\n")
                elif 'error' in result:
                    f.write(f"éŒ¯èª¤: {result['error']}\n")
                f.write("-" * 30 + "\n")
        
        self.logger.info(f"å„ªåŒ–å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    def convert_numpy_to_python(self, value):
        """å°‡numpyé¡å‹è½‰æ›ç‚ºPythonåŸç”Ÿé¡å‹"""
        import numpy as np
        
        # è™•ç†numpyæ•´æ•¸é¡å‹
        if isinstance(value, (np.integer, np.int8, np.int16, np.int32, np.int64)):
            return int(value)
        
        # è™•ç†numpyæµ®é»é¡å‹
        elif isinstance(value, (np.floating, np.float16, np.float32, np.float64)):
            return float(value)
        
        # è™•ç†numpyå¸ƒçˆ¾é¡å‹
        elif isinstance(value, np.bool_):
            return bool(value)
        
        # è™•ç†numpyå­—ç¬¦ä¸²é¡å‹
        elif isinstance(value, (np.str_, np.unicode_)):
            return str(value)
        
        # è™•ç†numpyæ—¥æœŸæ™‚é–“é¡å‹
        elif isinstance(value, np.datetime64):
            # è½‰æ›ç‚ºPython datetimeå­—ç¬¦ä¸²
            return pd.to_datetime(value).strftime('%Y-%m-%d %H:%M:%S')
        
        # è™•ç†pandasçš„Timestamp
        elif isinstance(value, pd.Timestamp):
            return value.strftime('%Y-%m-%d %H:%M:%S')
        
        # è™•ç†å…¶ä»–numpyæ¨™é‡é¡å‹
        elif hasattr(value, 'item'):
            # numpyæ¨™é‡éƒ½æœ‰item()æ–¹æ³•å¯ä»¥è½‰æ›ç‚ºPythonåŸç”Ÿé¡å‹
            return value.item()
        
        # å¦‚æœéƒ½ä¸æ˜¯ï¼Œç›´æ¥è¿”å›åŸå€¼
        else:
            return value
        
    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """è³‡æ–™é è™•ç†ï¼ˆå¢å¼·ç‰ˆï¼šè™•ç†numpyé¡å‹è½‰æ›ï¼‰"""
        import numpy as np
        
        # è™•ç†NaNå€¼
        df = df.where(pd.notnull(df), None)
        
        # ğŸ”§ é—œéµï¼šè½‰æ›æ‰€æœ‰numpyé¡å‹ç‚ºPythonåŸç”Ÿé¡å‹
        for col in df.columns:
            # æª¢æŸ¥åˆ—çš„æ•¸æ“šé¡å‹
            col_dtype = df[col].dtype
            
            # è™•ç†æ•´æ•¸é¡å‹
            if pd.api.types.is_integer_dtype(col_dtype):
                df[col] = df[col].apply(lambda x: int(x) if pd.notnull(x) else None)
            
            # è™•ç†æµ®é»é¡å‹
            elif pd.api.types.is_float_dtype(col_dtype):
                df[col] = df[col].apply(lambda x: float(x) if pd.notnull(x) else None)
            
            # è™•ç†å¸ƒçˆ¾é¡å‹
            elif pd.api.types.is_bool_dtype(col_dtype):
                df[col] = df[col].apply(lambda x: bool(x) if pd.notnull(x) else None)
            
            # è™•ç†æ—¥æœŸæ™‚é–“é¡å‹
            elif pd.api.types.is_datetime64_any_dtype(col_dtype):
                df[col] = df[col].apply(
                    lambda x: x.strftime('%Y-%m-%d %H:%M:%S') if pd.notnull(x) else None
                )
            
            # è™•ç†å­—ç¬¦ä¸²é¡å‹ä¸­çš„æ—¥æœŸæ ¼å¼
            elif df[col].dtype == 'object' and 'date' in col.lower():
                # å˜—è©¦è½‰æ›æ—¥æœŸæ ¼å¼
                try:
                    sample_val = df[col].dropna().iloc[0] if not df[col].dropna().empty else None
                    if sample_val and isinstance(sample_val, str):
                        if re.match(r'\d{4}[-/]\d{1,2}[-/]\d{1,2}', str(sample_val)):
                            df[col] = pd.to_datetime(df[col], errors='coerce').dt.strftime('%Y-%m-%d')
                except:
                    pass
        
        return df


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(description='MSSQL åˆ° MariaDB è³‡æ–™åº«é·ç§»å·¥å…·')
    parser.add_argument('--action', choices=['migrate', 'validate', 'optimize', 'clean', 'all'], 
                        default='all', help='åŸ·è¡Œå‹•ä½œ')
    parser.add_argument('--mssql-server', default='localhost\\SQLEXPRESS', help='MSSQLä¼ºæœå™¨')
    parser.add_argument('--mssql-database', default='dbmidterm', help='MSSQLè³‡æ–™åº«åç¨±')
    parser.add_argument('--mssql-username', default='', help='MSSQLä½¿ç”¨è€…åç¨±ï¼ˆåƒ…é™SQLé©—è­‰ï¼‰')
    parser.add_argument('--mssql-password', default='', help='MSSQLå¯†ç¢¼ï¼ˆåƒ…é™SQLé©—è­‰ï¼‰')
    parser.add_argument('--mssql-windows-auth', action='store_true', default=True, help='ä½¿ç”¨Windowsé©—è­‰ï¼ˆé è¨­å•Ÿç”¨ï¼‰')
    parser.add_argument('--mariadb-host', default='localhost', help='MariaDBä¸»æ©Ÿ')
    parser.add_argument('--mariadb-port', type=int, default=3306, help='MariaDBåŸ è™Ÿ')
    parser.add_argument('--mariadb-database', default='test', help='MariaDBè³‡æ–™åº«åç¨±')
    parser.add_argument('--mariadb-username', default='root', help='MariaDBä½¿ç”¨è€…åç¨±')
    parser.add_argument('--mariadb-password', default='12345', help='MariaDBå¯†ç¢¼')
    parser.add_argument('--batch-size', type=int, default=1000, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--schema', default='dbo', help='MSSQL Schema')
    
    args = parser.parse_args()
    
    # é…ç½®è³‡æ–™åº«é€£æ¥
    mssql_config = {
        'server': args.mssql_server,
        'database': args.mssql_database,
        'username': args.mssql_username,
        'password': args.mssql_password,
        'use_windows_auth': args.mssql_windows_auth
    }
    
    mariadb_config = {
        'host': args.mariadb_host,
        'port': args.mariadb_port,
        'database': args.mariadb_database,
        'username': args.mariadb_username,
        'password': args.mariadb_password
    }
    
    # å‰µå»ºé·ç§»å™¨
    migrator = DatabaseMigrator(mssql_config, mariadb_config, args.batch_size)
    
    try:
        # é¡¯ç¤ºé…ç½®ä¿¡æ¯
        print("ğŸ“‹ é·ç§»é…ç½®:")
        print(f"   MSSQL: {args.mssql_server}/{args.mssql_database}")
        print(f"   MariaDB: {args.mariadb_host}:{args.mariadb_port}/{args.mariadb_database}")
        print(f"   æ‰¹æ¬¡å¤§å°: {args.batch_size}")
        print(f"   å‹•ä½œ: {args.action}")
        
        if args.action == 'clean':
            print("\nğŸ—‘ï¸  é–‹å§‹æ¸…ç†MariaDBè¡¨æ ¼...")
            success = migrator.clean_mariadb_tables()
            if success:
                print("âœ… è¡¨æ ¼æ¸…ç†å®Œæˆ")
            else:
                print("âŒ è¡¨æ ¼æ¸…ç†å¤±æ•—")
        
        elif args.action == 'migrate':
            print("\nğŸš€ é–‹å§‹è³‡æ–™åº«é·ç§»...")
            success = migrator.migrate_full_database(args.schema)
            if success:
                print("âœ… è³‡æ–™åº«é·ç§»æˆåŠŸå®Œæˆ")
            else:
                print("âš ï¸  è³‡æ–™åº«é·ç§»éƒ¨åˆ†å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ—¥èªŒ")
        
        elif args.action == 'validate':
            print("\nğŸ” é–‹å§‹é·ç§»é©—è­‰...")
            
            # å…ˆæª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            existing_tables = migrator.check_mariadb_tables_exist()
            mssql_tables = migrator.get_mssql_tables(args.schema)
            
            missing_tables = []
            for table in mssql_tables:
                if not any(t.lower() == table.lower() for t in existing_tables):
                    missing_tables.append(table)
            
            if missing_tables:
                print(f"âš ï¸  ç™¼ç¾ {len(missing_tables)} å€‹è¡¨æ ¼ä¸å­˜åœ¨ï¼Œå…ˆåŸ·è¡Œé·ç§»...")
                print(f"   ç¼ºå¤±è¡¨æ ¼: {', '.join(missing_tables)}")
                
                # è‡ªå‹•åŸ·è¡Œé·ç§»
                migrate_success = migrator.migrate_full_database(args.schema)
                if not migrate_success:
                    print("âŒ è‡ªå‹•é·ç§»å¤±æ•—ï¼Œç„¡æ³•é€²è¡Œé©—è­‰")
                    sys.exit(1)
                
                print("âœ… è‡ªå‹•é·ç§»å®Œæˆï¼Œç¹¼çºŒé©—è­‰...")
            
            # åŸ·è¡Œé©—è­‰
            results = migrator.validate_migration_complete(args.schema)
            if results['overall_success']:
                print("âœ… é·ç§»é©—è­‰é€šé")
            else:
                print("âŒ é·ç§»é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥å ±å‘Š")
        
        elif args.action == 'optimize':
            print("\nâš¡ é–‹å§‹è³‡æ–™åº«å„ªåŒ–...")
            
            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            existing_tables = migrator.check_mariadb_tables_exist()
            if not existing_tables:
                print("âš ï¸  æ²’æœ‰æ‰¾åˆ°ä»»ä½•è¡¨æ ¼ï¼Œå…ˆåŸ·è¡Œé·ç§»...")
                migrate_success = migrator.migrate_full_database(args.schema)
                if not migrate_success:
                    print("âŒ è‡ªå‹•é·ç§»å¤±æ•—ï¼Œç„¡æ³•é€²è¡Œå„ªåŒ–")
                    sys.exit(1)
            
            migrator.optimize_mariadb_tables()
            print("âœ… è³‡æ–™åº«å„ªåŒ–å®Œæˆ")
        
        elif args.action == 'all':
            print("\nğŸš€ é–‹å§‹å®Œæ•´æµç¨‹...")
            
            # 1. é·ç§»
            print("ç¬¬1æ­¥ï¼šè³‡æ–™åº«é·ç§»")
            migrate_success = migrator.migrate_full_database(args.schema)
            if migrate_success:
                print("âœ… è³‡æ–™åº«é·ç§»æˆåŠŸå®Œæˆ")
            else:
                print("âš ï¸  è³‡æ–™åº«é·ç§»éƒ¨åˆ†å¤±æ•—ï¼Œä½†ç¹¼çºŒé©—è­‰...")
            
            # 2. é©—è­‰
            print("\nç¬¬2æ­¥ï¼šé·ç§»é©—è­‰")
            results = migrator.validate_migration_complete(args.schema)
            if results['overall_success']:
                print("âœ… é·ç§»é©—è­‰é€šé")
            else:
                print("âŒ é·ç§»é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥å ±å‘Š")
            
            # 3. å„ªåŒ–
            print("\nç¬¬3æ­¥ï¼šè³‡æ–™åº«å„ªåŒ–")
            migrator.optimize_mariadb_tables()
            print("âœ… è³‡æ–™åº«å„ªåŒ–å®Œæˆ")
            
            print("\nğŸ‰ å®Œæ•´æµç¨‹åŸ·è¡Œå®Œç•¢ï¼")
            
    except KeyboardInterrupt:
        print("\nâš ï¸  é·ç§»éç¨‹è¢«ä½¿ç”¨è€…ä¸­æ–·")
    except Exception as e:
        print(f"âŒ é·ç§»éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()